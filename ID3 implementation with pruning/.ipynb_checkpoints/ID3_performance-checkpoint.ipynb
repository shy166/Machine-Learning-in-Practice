{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('pa2train.txt',header=None,delimiter=' ')\n",
    "train = train.drop(23, axis = 1)\n",
    "test = pd.read_csv('pa2test.txt',header=None,delimiter=' ')\n",
    "test = test.drop(23, axis = 1)\n",
    "validate = pd.read_csv('pa2validation.txt',header=None,delimiter=' ')\n",
    "validate = validate.drop(23, axis = 1)\n",
    "features = pd.read_csv('pa2features.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize table with feature 1 - 22, label the 'target' columns\n",
    "train.columns = [i + 1 for i in range(22)] + ['target']\n",
    "test.columns = [i + 1 for i in range(22)] + ['target']\n",
    "validate.columns = [i + 1 for i in range(22)] + ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting data into feature DataFrame X and target Series y\n",
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "X_validate = validate.iloc[:, :-1]\n",
    "y_validate = validate.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classifier ###\n",
    "class ID3():\n",
    "    '''Initialize ID3 Class'''\n",
    "    class Node():\n",
    "        '''Tree Node'''\n",
    "        def __init__(self, feature = None, threshold= None, samples = None, label = None):\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.samples = samples\n",
    "            self.label = label\n",
    "            self.isleft = None\n",
    "            self.parent = None\n",
    "        def set_left(self, other): \n",
    "            '''Set left child'''\n",
    "            self.left = other\n",
    "            other.isleft = True\n",
    "            other.parent = self\n",
    "        def set_right(self, other):\n",
    "            '''Set right child'''\n",
    "            self.right = other\n",
    "            other.isleft = False\n",
    "            other.parent = self\n",
    "        def is_leaf(self):\n",
    "            '''Determine if the Node is leaf'''\n",
    "            return self.left == None and self.right == None\n",
    "        def print_info(self):\n",
    "            '''Print info of the Node'''\n",
    "            if self.is_leaf():\n",
    "                print(self.label)\n",
    "            else:\n",
    "                print(self.feature, self.threshold, self.samples)\n",
    "    def _H(self, S):\n",
    "        '''Helper function of Getting Entropy of S'''\n",
    "        p = np.unique(S,return_counts=True)[1]/len(S)\n",
    "        entropy = np.sum(-p*(np.log2(p)))\n",
    "        return entropy\n",
    "\n",
    "    def _IG(self,train,target,threshold):\n",
    "        '''Helper function of Getting Information Gain of training set over target column with certain threshold'''\n",
    "        t1 = target.loc[train>=threshold]\n",
    "        t2 = target.loc[train<threshold]\n",
    "\n",
    "        p = len(t1)/len(train)\n",
    "        return self._H(target)-p*self._H(t1)-(1-p)*self._H(t2)\n",
    "    def __init__(self):\n",
    "        '''Constructor of ID3'''\n",
    "        self.tree = None #A decision tree in .tree\n",
    "    \n",
    "    def _ID3_func(self,X,y,_mode,_prev_mode):\n",
    "        '''Helper function to build the decision tree'''\n",
    "        ### base cases ###:\n",
    "        labels = y.unique()\n",
    "        # When the dataset is pure\n",
    "        if len(labels)==1:\n",
    "            node = self.Node(label=labels[0])\n",
    "            return node\n",
    "        # When the dataset is empty Node as the mode overall distribution\n",
    "        if len(X) == 0:\n",
    "            return self.Node(label = _mode)\n",
    "        if len(X.columns) == 0:\n",
    "        # When the dataset's feature is empty, label the Node as previous mode\n",
    "            return self.Node(label = _prev_mode)\n",
    "        \n",
    "        ### Calculate the entropy & best feature & best threshold###\n",
    "        gain = []\n",
    "        threshold = []\n",
    "        for feature in X.columns:\n",
    "            x = X.loc[:,feature]\n",
    "            temp = np.unique(x)\n",
    "            candidates = np.diff(temp)/2+temp[:-1] \n",
    "            ig = [self._IG(x,y,c) for c in candidates]\n",
    "            if len(ig) == 0:\n",
    "                gain.append(-np.inf)\n",
    "                threshold.append(-np.inf)\n",
    "                continue\n",
    "            else:\n",
    "                gain.append(np.amax(ig))\n",
    "                threshold.append(candidates[np.argmax(ig)])\n",
    "        ix = np.argmax(gain)\n",
    "        best_feature = X.columns[ix]\n",
    "        best_threshold = threshold[ix]\n",
    "        ### Construct the Tree Node ###\n",
    "        tree = self.Node(feature = best_feature,threshold = best_threshold, samples = len(X))\n",
    "        # Splitting the dataset into two piece\n",
    "        mask = X[best_feature]<best_threshold\n",
    "        X_left = X.loc[mask]\n",
    "        y_left = y.loc[mask]\n",
    "        X_right = X.loc[~mask]\n",
    "        y_right = y.loc[~mask]\n",
    "        ### Create left node and right node by recursion ###\n",
    "        left_node = self._ID3_func(X_left, y_left, _mode, y.unique()[0])\n",
    "        right_node = self._ID3_func(X_right, y_right, _mode, y.unique()[0])\n",
    "        tree.set_left(left_node)\n",
    "        tree.set_right(right_node)\n",
    "        return tree\n",
    "    def fit(self, X, y):\n",
    "        '''To fit the decision tree to classifier'''\n",
    "        _mode = y.unique()[0]\n",
    "        self.tree = self._ID3_func(X, y, _mode, _mode)\n",
    "    \n",
    "    def _predict(self, Xi, curr = None):\n",
    "        '''Helper function for Predict Xi'''\n",
    "        if curr == None:\n",
    "            # If it curr is None, start from root\n",
    "            curr = self.tree\n",
    "        if curr.is_leaf():\n",
    "            # Base Case, if current node is leaf, return the label\n",
    "            to_return = curr.label\n",
    "            return to_return\n",
    "        # Get splitting decision\n",
    "        feature, threshold = curr.feature, curr.threshold\n",
    "        # Classify the Xi into next node\n",
    "        if Xi[feature] < threshold:\n",
    "            curr = curr.left\n",
    "            return self._predict(Xi, curr)\n",
    "        else:\n",
    "            curr = curr.right\n",
    "            return self._predict(Xi, curr)\n",
    "    def predict(self, X):\n",
    "        '''funtion to predict X dataset.'''\n",
    "        return pd.Series([self._predict(X.iloc[Xi,:]) for Xi in range(X.shape[0])], index = X.index)\n",
    "    def score(self, X, y):\n",
    "        '''Get the accuracy of prediction'''\n",
    "        return (self.predict(X) == y).mean()\n",
    "\n",
    "            \n",
    "    def _get_sample(self, X, Node):\n",
    "        ''' Get the samples in this Node by reverse the tree'''\n",
    "        if Node == self.tree:\n",
    "            # Base Case Node is root, return sample\n",
    "            return X\n",
    "        # Traverse back to parent Node with parent's decision\n",
    "        elif Node.isleft == True:\n",
    "            feature, threshold = Node.parent.feature, Node.parent.threshold\n",
    "            X = X[X[feature] < threshold]\n",
    "            return self._get_sample(X, Node.parent)\n",
    "        elif Node.isleft == False:\n",
    "            feature, threshold = Node.parent.feature, Node.parent.threshold\n",
    "            X = X[X[feature] >= threshold]\n",
    "            return self._get_sample(X, Node.parent)\n",
    "    def _bfs(self):\n",
    "        '''traverse the decision tree by bfs'''\n",
    "        thislevel = [self.tree]\n",
    "        to_return = thislevel\n",
    "        while thislevel:\n",
    "            nextlevel = list()\n",
    "            for n in thislevel:\n",
    "                if n.left: \n",
    "                    nextlevel.append(n.left)\n",
    "                if n.right: \n",
    "                    nextlevel.append(n.right)\n",
    "\n",
    "            thislevel = nextlevel\n",
    "            to_return += nextlevel\n",
    "        return to_return #return as a list\n",
    "    \n",
    "    def prune(self, X, y, N):\n",
    "        nodes = self._bfs()\n",
    "        # Looping over the bfs of each node by bfs\n",
    "        for node in nodes:\n",
    "            # Get samples in the node\n",
    "            X_sample = self._get_sample(X, node)\n",
    "            y_sample = y[y.index.isin(X_sample.index)]\n",
    "            # Calculating err of classifier\n",
    "            err = 1 - self.score(X_sample, y_sample)\n",
    "            # Get the most freq label of the prediction\n",
    "            mode_i = self.predict(X_sample).value_counts().idxmax()\n",
    "            # Calculate Prune decision\n",
    "            prune_pred = pd.Series([mode_i for Xi in range(len(X_sample))], index = X_sample.index)\n",
    "            err_hat = 1 - (prune_pred == y_sample).mean()\n",
    "            # Replace Node if err_hat is smaller or equal\n",
    "            if err_hat <= err:\n",
    "                new_node = self.Node(label = mode_i)\n",
    "                if node.isleft == True:\n",
    "                    node.parent.set_left(new_node)\n",
    "                elif node.isleft == False:\n",
    "                    node.parent.set_right(new_node)\n",
    "                else:\n",
    "                    node = new_node\n",
    "                N -= 1\n",
    "            # Stopping\n",
    "            if N == 0:\n",
    "                break\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ID3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(Node, height):\n",
    "    '''Helper funtion to print tree'''\n",
    "    def print_given_level(root, level):\n",
    "        if root.is_leaf():\n",
    "            print(root.label)\n",
    "            return\n",
    "        elif level == 1:\n",
    "            print((root.feature, root.threshold, root.samples), end = '      ')\n",
    "            return\n",
    "        else:\n",
    "            print_given_level(root.left, level - 1)\n",
    "            print_given_level(root.right, level - 1)\n",
    "        \n",
    "    \n",
    "    for i in range(height):  \n",
    "        print((height - i) * '               ', end = '')\n",
    "        print_given_level(Node, i+1)\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             (5, 0.5, 2000)      \n",
      "                              (1, 415000.0, 1319)      (5, 1.5, 681)      \n",
      "               (17, 2506.5, 1284)      (21, 208.0, 35)      (20, 584.5, 292)      (21, 2006.0, 389)      \n"
     ]
    }
   ],
   "source": [
    "print_tree(clf.tree, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the first 3 depth Nodes of the decision tree without pruning, For example,the printing message of one node: (5, 0.5, 2000) means the feature 5 with < 0.5 on left >= 0.5 on right, and 2000 samples in this node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(\n",
    "        {\n",
    "            'Training Error': 1 - clf.score(X_train, y_train),\n",
    "            'Validation Error' : 1 - clf.score(X_validate, y_validate),\n",
    "            'Test Error': 1 - clf.score(X_test, y_test)\n",
    "        }, index = ['without pruning']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>without pruning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training Error  Validation Error  Test Error\n",
       "without pruning             0.0             0.179       0.173"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.prune(X_validate, y_validate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(\n",
    "        {\n",
    "            'Training Error': 1 - clf.score(X_train, y_train),\n",
    "            'Validation Error' : 1 - clf.score(X_validate, y_validate),\n",
    "            'Test Error': 1 - clf.score(X_test, y_test)\n",
    "        }, index = pd.Series([1],name = 'Prune')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ID3()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.prune(X_validate, y_validate, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.append(pd.DataFrame(\n",
    "        {\n",
    "            'Training Error': 1 - clf.score(X_train, y_train),\n",
    "            'Validation Error' : 1 - clf.score(X_validate, y_validate),\n",
    "            'Test Error': 1 - clf.score(X_test, y_test)\n",
    "        }, index = pd.Series([2],name = 'Prune')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Error  Validation Error  Test Error\n",
       "Prune                                              \n",
       "1              0.0845             0.122       0.117\n",
       "2              0.1050             0.107       0.103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output) #Display the error of prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# see the which node is pruned\n",
    "print(clf.tree.left.label, clf.tree.right.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we observe that the left child and right child of root have been pruned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the tree in question 1, and in previous question, we found that we pruned the left and right node from the root, it still has low validation error and test error. Then the fifth feature is the most salient feature. And feature 1, 17, 20 21 are also relevent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAYMENT_DELAY_SEPTEMBER\n"
     ]
    }
   ],
   "source": [
    "print(features.iloc[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LIMIT_BAL', 'PAY_AMT1', 'PAY_AMT4', 'PAY_AMT5']\n"
     ]
    }
   ],
   "source": [
    "print(features.iloc[[0,16,19,20]][0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the cell above shown, the fifth feature is 'PAYMENT_DELAY_SEPTEMBER', which is the most salient feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'LIMIT_BAL', 'PAY_AMT1', 'PAY_AMT4', 'PAY_AMT5' are also relevent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
